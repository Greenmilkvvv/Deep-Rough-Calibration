{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97217e91",
   "metadata": {},
   "source": [
    "# Calibration with NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b35a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_pricing(\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=88, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch \n",
    "import scipy \n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# 导入模型\n",
    "from NN_Training.NN.nn import NN_pricing\n",
    "\n",
    "# 评估使用 cpu\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# 设置参数为 4 个\n",
    "hyperparams = { \n",
    "    'input_dim': 4, \n",
    "    'hidden_dim': 64, \n",
    "    'hidden_nums': 10,\n",
    "    'output_dim': 88,\n",
    "    'block_layer_nums': 3\n",
    "}\n",
    "\n",
    "model = NN_pricing(hyperparams=hyperparams).to(device=device, dtype=torch.float64)\n",
    "\n",
    "\n",
    "model_state = torch.load( \n",
    "    '../Data/Models/nn_rBergomi.pth'\n",
    ")\n",
    "model.load_state_dict(model_state)\n",
    "\n",
    "# 设置为 eval mode\n",
    "model.eval()\n",
    "model.to(device=device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bebf5a9",
   "metadata": {},
   "source": [
    "## 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b95a18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数形状：(40000, 4)\n",
      "隐含波动率曲面形状：(40000, 88)\n",
      "参数上界: [ 0.16      4.       -0.100011  0.499998]\n",
      "参数下界: [ 0.0100133  0.300028  -0.949934   0.0250066]\n",
      "训练集形状：torch.Size([34000, 4])\n",
      "测试集形状：torch.Size([6000, 4])\n"
     ]
    }
   ],
   "source": [
    "# 数据集\n",
    "import gzip\n",
    "f = gzip.GzipFile(\n",
    "    filename = r\"../Data/rBergomiTrainSet.txt.gz\", \n",
    "    mode = \"r\"\n",
    ")\n",
    "\n",
    "data = np.load(f)\n",
    "xx, yy = data[:, :4], data[:, 4:]\n",
    "\n",
    "strikes=np.array([0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5 ])\n",
    "maturities=np.array([0.1,0.3,0.6,0.9,1.2,1.5,1.8,2.0 ])\n",
    "\n",
    "# xx: 参数\n",
    "## 前 4 列代表网格所对应的参数\n",
    "xx = data[:, :4]\n",
    "print(f\"参数形状：{xx.shape}\")\n",
    "\n",
    "# yy: 隐含波动率曲面 \n",
    "# 后 88 列表示隐含波动率曲面 8 * 11 = 88\n",
    "yy = data[:, 4:]\n",
    "print(f\"隐含波动率曲面形状：{yy.shape}\")\n",
    "\n",
    "# 参数\n",
    "print(f\"参数上界: {np.max(xx, axis=0)}\")\n",
    "print(f\"参数下界: {np.min(xx, axis=0)}\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# from NN_Training.rBergomi_nn_pricer import x_transform, x_inv_transform, y_transform, y_inv_transform, params_scaler, params_inv_scaler\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(xx, yy, test_size=0.15, random_state=42)\n",
    "\n",
    "scale_x, scale_y = StandardScaler(), StandardScaler()\n",
    "\n",
    "\n",
    "# 工具函数——数据标准化\n",
    "def x_transform(train_data, test_data): \n",
    "    return scale_x.fit_transform(train_data), scale_x.transform(test_data)\n",
    "\n",
    "def x_inv_transform(x):\n",
    "    return scale_x.inverse_transform(x)\n",
    "\n",
    "def y_transform(train_data, test_data): \n",
    "    return scale_y.fit_transform(train_data), scale_y.transform(test_data)\n",
    "\n",
    "def y_inv_transform(y):\n",
    "    return scale_y.inverse_transform(y)\n",
    "\n",
    "\n",
    "# 训练集的 Upper and Lower Bounds\n",
    "upper_bound = np.array([0.16,4,-0.1,0.5])\n",
    "lower_bound = np.array([0.01,0.3,-0.95,0.025])\n",
    "\n",
    "def params_scaler(x): \n",
    "    return (x - (upper_bound+lower_bound) / 2 ) * 2 / (upper_bound-lower_bound)\n",
    "\n",
    "def params_inv_scaler(x):\n",
    "    return x * (upper_bound-lower_bound) / 2 + (upper_bound+lower_bound) / 2\n",
    "\n",
    "\n",
    "x_train_transform = params_scaler(x_train)\n",
    "x_test_transform = params_scaler(x_test)\n",
    "\n",
    "y_train_transform, y_test_transform = y_transform(y_train, y_test)\n",
    "\n",
    "\n",
    "train_data = (torch.from_numpy(x_train_transform).to(device=device),torch.from_numpy(y_train_transform).to(device=device))\n",
    "\n",
    "test_data = (torch.from_numpy(x_test_transform).to(device=device),torch.from_numpy(y_test_transform).to(device=device))\n",
    "\n",
    "\n",
    "print(f\"训练集形状：{train_data[0].shape}\")\n",
    "print(f\"测试集形状：{test_data[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf4e8c",
   "metadata": {},
   "source": [
    "## 校准优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1773d79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS 优化结果 (前 10 个): [[ 0.2718526  -0.84177326 -0.44196364 -0.11724242]\n",
      " [ 0.92646886  0.63670469  0.14527745  0.1025588 ]\n",
      " [ 0.10138511 -0.08402274 -0.21554354 -0.49044345]\n",
      " [-0.68391753 -0.53723164 -0.16574831 -0.1774751 ]\n",
      " [-0.12698649 -0.8060794   0.39369799 -0.64026452]\n",
      " [-0.77693773  0.65927194 -0.4914505  -0.37049258]\n",
      " [ 0.95820271  0.64735446  0.09682647 -0.02687364]\n",
      " [-0.11308724  0.16684554 -0.53941525  0.01480419]\n",
      " [-0.95194173  0.5748682   0.16220536  0.19815356]\n",
      " [-0.30674038 -0.92243137  0.86765812 -0.1464441 ]]\n",
      "LBFGS 优化时间 (前 10 个): [0.22574258 0.1875999  0.1952157  0.21575189 0.21120024 0.19905877\n",
      " 0.17989588 0.19130325 0.1920712  0.21114159]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_MSE = nn.MSELoss()\n",
    "\n",
    "vol_model = y_inv_transform(model(test_data[0]).detach().numpy())\n",
    "vol_real = y_test\n",
    "\n",
    "error_real = np.abs(vol_model-vol_real)\n",
    "error_relative = error_real/vol_real\n",
    "\n",
    "np.mean(error_relative)\n",
    "\n",
    "\n",
    "# 使用 LBFGS 优化器\n",
    "from optimization_utils import calibrate_with_torch_lbfgs\n",
    "\n",
    "Approx, Timing = calibrate_with_torch_lbfgs(model, y_test_transform, device='cpu')\n",
    "\n",
    "\n",
    "print(f\"LBFGS 优化结果 (前 10 个): {Approx[:10]}\")\n",
    "print(f\"LBFGS 优化时间 (前 10 个): {Timing[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424305f",
   "metadata": {},
   "source": [
    "## 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f314496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "titles = [\"$\\\\xi_0$\",\"$\\\\omega$\",\"$\\\\rho$\",\"$H$\"]\n",
    "\n",
    "average = np.zeros([4,6000])\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "for u in range(4): \n",
    "    ax = plt.subplot(2, 2, u+1)\n",
    "    x = x_test[:6000, u]\n",
    "    plt.plot( \n",
    "        x, \n",
    "        100 * np.abs( Approx[:6000, u] - x ) / np.abs(x), \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
